[
  {
    "api_model_id": "aion-labs/aion-1.0",
    "provider_api_model_id": "aion-labs:aion-labs/aion-1.0",
    "provider_model_slug": "aion-labs/aion-1.0",
    "internal_model_id": "aion-labs/aion-1-0-2025-01-29",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text",
    "output_modalities": "text",
    "effective_from": null,
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "include_reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "temperature",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "top_p",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "aion-labs/aion-1.0-mini",
    "provider_api_model_id": "aion-labs:aion-labs/aion-1.0-mini",
    "provider_model_slug": "aion-labs/aion-1.0-mini",
    "internal_model_id": "aion-labs/aion-1-0-mini-2025-01-29",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text",
    "output_modalities": "text",
    "effective_from": null,
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "include_reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "temperature",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "top_p",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "aion-labs/aion-2.0",
    "provider_api_model_id": "aion-labs:aion-labs/aion-2.0",
    "provider_model_slug": "aion-labs/aion-2.0",
    "internal_model_id": "aion-labs/aion-2-0-2025-12-21",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text",
    "output_modalities": "text",
    "effective_from": null,
    "effective_to": null,
    "capabilities": []
  },
  {
    "api_model_id": "aion-labs/aion-rp-llama-3.1-8b",
    "provider_api_model_id": "aion-labs:aion-labs/aion-rp-llama-3.1-8b",
    "provider_model_slug": "aion-labs/aion-rp-llama-3.1-8b",
    "internal_model_id": "aion-labs/aion-rp-llama-3-1-8b-2024-11-30",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text",
    "output_modalities": "text",
    "effective_from": null,
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "temperature",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "top_p",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  }
]