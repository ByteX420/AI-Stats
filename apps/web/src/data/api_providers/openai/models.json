[
  {
    "api_model_id": "openai/babbage-002",
    "provider_api_model_id": "openai:openai/babbage-002",
    "provider_model_slug": "babbage-002",
    "internal_model_id": "openai/babbage-002-2023-08-22",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2023-08-22T00:00:00",
    "effective_to": "2026-09-28T00:00:00",
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tool_choice",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tools",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/chatgpt-4o",
    "provider_api_model_id": "openai:openai/chatgpt-4o",
    "provider_model_slug": "chatgpt-4o-latest",
    "internal_model_id": "openai/chatgpt-4o-2024-05-13",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2024-05-13T00:00:00",
    "effective_to": "2026-02-17T00:00:00",
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "frequency_penalty",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "logit_bias",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "logprobs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "presence_penalty",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "stop",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "temperature",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "top_logprobs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "top_p",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/davinci-002",
    "provider_api_model_id": "openai:openai/davinci-002",
    "provider_model_slug": "davinci-002",
    "internal_model_id": "openai/davinci-002-2023-08-22",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2023-08-22T00:00:00",
    "effective_to": "2026-09-28T00:00:00",
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tool_choice",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tools",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/gpt-3.5-turbo",
    "provider_api_model_id": "openai:openai/gpt-3.5-turbo",
    "provider_model_slug": "gpt-3.5-turbo-1106",
    "internal_model_id": "openai/gpt-3-5-turbo-2023-11-06",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": "text",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2023-11-06T00:00:00",
    "effective_to": "2026-09-28T00:00:00",
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "frequency_penalty",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "logit_bias",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "logprobs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "presence_penalty",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "stop",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "temperature",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tool_choice",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tools",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "top_logprobs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "top_p",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/gpt-3.5-turbo-16k",
    "provider_api_model_id": "openai:openai/gpt-3.5-turbo-16k",
    "provider_model_slug": "gpt-3.5-turbo-16k",
    "internal_model_id": "openai/gpt-3-5-turbo-16k-0613-2023-06-13",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": "text",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2023-06-13T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "frequency_penalty",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "logit_bias",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "logprobs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "presence_penalty",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "stop",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "temperature",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tool_choice",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tools",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "top_logprobs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "top_p",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/gpt-4.1",
    "provider_api_model_id": "openai:openai/gpt-4.1",
    "provider_model_slug": "gpt-4.1-2025-04-14",
    "internal_model_id": "openai/gpt-4-1-2025-04-14",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2025-04-14T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "temperature",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tool_choice",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tools",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "top_p",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/gpt-4.1-mini",
    "provider_api_model_id": "openai:openai/gpt-4.1-mini",
    "provider_model_slug": "gpt-4.1-mini-2025-04-14",
    "internal_model_id": "openai/gpt-4-1-mini-2025-04-14",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2025-04-14T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "temperature",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tool_choice",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tools",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "top_p",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/gpt-4.1-nano",
    "provider_api_model_id": "openai:openai/gpt-4.1-nano",
    "provider_model_slug": "gpt-4.1-nano-2025-04-14",
    "internal_model_id": "openai/gpt-4-1-nano-2025-04-14",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2025-04-14T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "temperature",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tool_choice",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tools",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "top_p",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/gpt-4-2023-03-14",
    "provider_api_model_id": "openai:openai/gpt-4-2023-03-14",
    "provider_model_slug": "gpt-4-0314",
    "internal_model_id": "openai/gpt-4-2023-03-14",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2023-03-14T00:00:00",
    "effective_to": "2026-03-26T00:00:00",
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "frequency_penalty",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "logit_bias",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "logprobs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "presence_penalty",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "stop",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "temperature",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tool_choice",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tools",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "top_logprobs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "top_p",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/gpt-4-2023-06-13",
    "provider_api_model_id": "openai:openai/gpt-4-2023-06-13",
    "provider_model_slug": "gpt-4-0613",
    "internal_model_id": "openai/gpt-4-2023-06-13",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2023-06-13T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "frequency_penalty",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "logit_bias",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "logprobs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "presence_penalty",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "stop",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "temperature",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tool_choice",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tools",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "top_logprobs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "top_p",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/gpt-4o-2024-05-13",
    "provider_api_model_id": "openai:openai/gpt-4o-2024-05-13",
    "provider_model_slug": "gpt-4o-2024-05-13",
    "internal_model_id": "openai/gpt-4o-2024-05-13",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2024-05-13T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "frequency_penalty",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "logit_bias",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "logprobs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "presence_penalty",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "stop",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "temperature",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tool_choice",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tools",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "top_logprobs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "top_p",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "web_search_options",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/gpt-4o-2024-08-06",
    "provider_api_model_id": "openai:openai/gpt-4o-2024-08-06",
    "provider_model_slug": "gpt-4o-2024-11-20",
    "internal_model_id": "openai/gpt-4o-2024-08-06",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2024-08-06T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "frequency_penalty",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "logit_bias",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "logprobs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "presence_penalty",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "stop",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "temperature",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tool_choice",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tools",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "top_logprobs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "top_p",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "web_search_options",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/gpt-4o-2024-11-20",
    "provider_api_model_id": "openai:openai/gpt-4o-2024-11-20",
    "provider_model_slug": "gpt-4o-2024-08-06",
    "internal_model_id": "openai/gpt-4o-2024-11-20",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2024-11-20T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "frequency_penalty",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "logit_bias",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "logprobs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "presence_penalty",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "stop",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "temperature",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tool_choice",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tools",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "top_logprobs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "top_p",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "web_search_options",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/gpt-4o-mini",
    "provider_api_model_id": "openai:openai/gpt-4o-mini",
    "provider_model_slug": "gpt-4o-mini-2024-07-18",
    "internal_model_id": "openai/gpt-4o-mini-2024-07-18",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2024-07-18T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "frequency_penalty",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "logit_bias",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "logprobs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "presence_penalty",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "stop",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "temperature",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tool_choice",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tools",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "top_logprobs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "top_p",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "web_search_options",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/gpt-5",
    "provider_api_model_id": "openai:openai/gpt-5",
    "provider_model_slug": "gpt-5-2025-08-07",
    "internal_model_id": "openai/gpt-5-2025-08-07",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2025-08-07T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "include_reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tool_choice",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tools",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/gpt-5.1",
    "provider_api_model_id": "openai:openai/gpt-5.1",
    "provider_model_slug": "gpt-5.1-2025-11-13",
    "internal_model_id": "openai/gpt-5-1-2025-11-12",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2025-11-12T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "include_reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tool_choice",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tools",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/gpt-5.1-chat",
    "provider_api_model_id": "openai:openai/gpt-5.1-chat",
    "provider_model_slug": "gpt-5.1-chat-latest",
    "internal_model_id": "openai/gpt-5-1-chat-2025-11-13",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2025-11-13T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tool_choice",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tools",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/gpt-5.1-codex",
    "provider_api_model_id": "openai:openai/gpt-5.1-codex",
    "provider_model_slug": "gpt-5.1-codex",
    "internal_model_id": "openai/gpt-5-1-codex-2025-11-13",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2025-11-13T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "include_reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tool_choice",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tools",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/gpt-5.1-codex-max",
    "provider_api_model_id": "openai:openai/gpt-5.1-codex-max",
    "provider_model_slug": "gpt-5.1-codex-max",
    "internal_model_id": "openai/gpt-5-1-codex-max-2025-11-19",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2025-11-19T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "include_reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tool_choice",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tools",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/gpt-5.1-codex-mini",
    "provider_api_model_id": "openai:openai/gpt-5.1-codex-mini",
    "provider_model_slug": "gpt-5.1-codex-mini",
    "internal_model_id": "openai/gpt-5-1-codex-mini-2025-11-13",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2025-11-13T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "include_reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tool_choice",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tools",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/gpt-5.2",
    "provider_api_model_id": "openai:openai/gpt-5.2",
    "provider_model_slug": "gpt-5.2-2025-12-11",
    "internal_model_id": "openai/gpt-5-2-2025-12-11",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2025-12-11T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "include_reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tool_choice",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tools",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/gpt-5.2-chat",
    "provider_api_model_id": "openai:openai/gpt-5.2-chat",
    "provider_model_slug": "gpt-5.2-chat-latest",
    "internal_model_id": "openai/gpt-5-2-chat-2025-12-11",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2025-12-11T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tool_choice",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tools",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/gpt-5.2-codex",
    "provider_api_model_id": "openai:openai/gpt-5.2-codex",
    "provider_model_slug": "gpt-5.2-codex",
    "internal_model_id": "openai/gpt-5-2-codex-2025-12-18",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2026-01-14T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "frequency_penalty",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "include_reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "logit_bias",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "logprobs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "presence_penalty",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "stop",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tool_choice",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tools",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "top_logprobs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/gpt-5.2-pro",
    "provider_api_model_id": "openai:openai/gpt-5.2-pro",
    "provider_model_slug": "gpt-5.2-pro-2025-12-11",
    "internal_model_id": "openai/gpt-5-2-pro-2025-12-11",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2025-12-11T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "include_reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tool_choice",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tools",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/gpt-5-chat",
    "provider_api_model_id": "openai:openai/gpt-5-chat",
    "provider_model_slug": "gpt-5-chat-latest",
    "internal_model_id": "openai/gpt-5-chat-2025-08-07",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2025-08-07T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/gpt-5-codex",
    "provider_api_model_id": "openai:openai/gpt-5-codex",
    "provider_model_slug": "gpt-5-codex",
    "internal_model_id": "openai/gpt-5-codex-2025-09-15",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2025-09-15T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "include_reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tool_choice",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tools",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/gpt-5-mini",
    "provider_api_model_id": "openai:openai/gpt-5-mini",
    "provider_model_slug": "gpt-5-mini-2025-08-07",
    "internal_model_id": "openai/gpt-5-mini-2025-08-07",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2025-08-07T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "include_reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tool_choice",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tools",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/gpt-5-nano",
    "provider_api_model_id": "openai:openai/gpt-5-nano",
    "provider_model_slug": "gpt-5-nano-2025-08-07",
    "internal_model_id": "openai/gpt-5-nano-2025-08-07",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2025-08-07T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "include_reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tool_choice",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tools",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/gpt-5-pro",
    "provider_api_model_id": "openai:openai/gpt-5-pro",
    "provider_model_slug": "gpt-5-pro-2025-10-06",
    "internal_model_id": "openai/gpt-5-pro-2025-08-07",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2025-08-07T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "include_reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tool_choice",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tools",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/o1",
    "provider_api_model_id": "openai:openai/o1",
    "provider_model_slug": "o1-2024-12-17",
    "internal_model_id": "openai/o1-2024-12-17",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2024-12-17T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tool_choice",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tools",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/o1-pro",
    "provider_api_model_id": "openai:openai/o1-pro",
    "provider_model_slug": "o1-pro-2025-03-19",
    "internal_model_id": "openai/o1-pro-2025-03-19",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2025-03-19T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "include_reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/o3",
    "provider_api_model_id": "openai:openai/o3",
    "provider_model_slug": "o3-2025-04-16",
    "internal_model_id": "openai/o3-2025-04-16",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2025-04-16T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "include_reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tool_choice",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tools",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/o3-deep-research",
    "provider_api_model_id": "openai:openai/o3-deep-research",
    "provider_model_slug": "o3-deep-research-2025-06-26",
    "internal_model_id": "openai/o3-deep-research-2025-06-26",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2025-06-26T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "frequency_penalty",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "include_reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "logit_bias",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "logprobs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "presence_penalty",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "stop",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "temperature",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tool_choice",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tools",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "top_logprobs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "top_p",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/o3-mini",
    "provider_api_model_id": "openai:openai/o3-mini",
    "provider_model_slug": "o3-mini-2025-01-31",
    "internal_model_id": "openai/o3-mini-2025-01-30",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2025-01-30T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tool_choice",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tools",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/o3-pro",
    "provider_api_model_id": "openai:openai/o3-pro",
    "provider_model_slug": "o3-pro-2025-06-10",
    "internal_model_id": "openai/o3-pro-2025-06-10",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2025-06-10T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "include_reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tool_choice",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tools",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/o4-mini",
    "provider_api_model_id": "openai:openai/o4-mini",
    "provider_model_slug": "o4-mini-2025-04-16",
    "internal_model_id": "openai/o4-mini-2025-04-16",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2025-04-16T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "include_reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tool_choice",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tools",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/o4-mini-deep-research",
    "provider_api_model_id": "openai:openai/o4-mini-deep-research",
    "provider_model_slug": "o4-mini-deep-research-2025-06-26",
    "internal_model_id": "openai/o4-mini-deep-research-2025-06-26",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2025-06-26T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "frequency_penalty",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "include_reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "logit_bias",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "logprobs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "presence_penalty",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "reasoning",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "stop",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "temperature",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tool_choice",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "tools",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "top_logprobs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "top_p",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/omni-moderation",
    "provider_api_model_id": "openai:openai/omni-moderation",
    "provider_model_slug": "omni-moderation-latest",
    "internal_model_id": "openai/omni-moderation-2024-09-26",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2024-09-26T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": []
      }
    ]
  },
  {
    "api_model_id": "openai/text-embedding-3-large",
    "provider_api_model_id": "openai:openai/text-embedding-3-large",
    "provider_model_slug": "text-embedding-3-large",
    "internal_model_id": "openai/text-embedding-3-large-2024-01-25",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text",
    "output_modalities": "embeddings",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2024-01-25T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.embed",
        "status": "active",
        "params": []
      }
    ]
  },
  {
    "api_model_id": "openai/text-embedding-3-small",
    "provider_api_model_id": "openai:openai/text-embedding-3-small",
    "provider_model_slug": "text-embedding-3-small",
    "internal_model_id": "openai/text-embedding-3-small-2024-01-25",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text",
    "output_modalities": "embeddings",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2024-01-25T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.embed",
        "status": "active",
        "params": []
      }
    ]
  },
  {
    "api_model_id": "openai/text-embedding-ada-002",
    "provider_api_model_id": "openai:openai/text-embedding-ada-002",
    "provider_model_slug": "text-embedding-ada-002",
    "internal_model_id": "openai/text-embedding-ada-002-2022-12-15",
    "is_active_gateway": true,
    "quantization_scheme": null,
    "input_modalities": "text",
    "output_modalities": "embeddings",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2022-12-15T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.embed",
        "status": "active",
        "params": []
      }
    ]
  },
  {
    "api_model_id": "openai/ada",
    "provider_api_model_id": "openai:openai/ada",
    "provider_model_slug": "ada",
    "internal_model_id": "openai/ada-2020-06-11",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": "text",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2020-06-11T00:00:00",
    "effective_to": "2024-01-04T00:00:00",
    "capabilities": []
  },
  {
    "api_model_id": "openai/babbage",
    "provider_api_model_id": "openai:openai/babbage",
    "provider_model_slug": "babbage",
    "internal_model_id": "openai/babbage-2020-06-11",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": "text",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2020-06-11T00:00:00",
    "effective_to": "2024-01-04T00:00:00",
    "capabilities": []
  },
  {
    "api_model_id": "openai/chatgpt-image-latest",
    "provider_api_model_id": "openai:openai/chatgpt-image-latest",
    "provider_model_slug": "chatgpt-image-latest",
    "internal_model_id": "openai/chatgpt-image-latest-2025-12-16",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text,image",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2025-12-16T00:00:00",
    "effective_to": null,
    "capabilities": []
  },
  {
    "api_model_id": "openai/codex-mini",
    "provider_api_model_id": "openai:openai/codex-mini",
    "provider_model_slug": null,
    "internal_model_id": "openai/codex-mini-2025-05-16",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2025-05-16T00:00:00",
    "effective_to": "2026-01-16T00:00:00",
    "capabilities": []
  },
  {
    "api_model_id": "openai/computer-use-preview",
    "provider_api_model_id": "openai:openai/computer-use-preview",
    "provider_model_slug": "computer-use-preview-2025-03-11",
    "internal_model_id": "openai/computer-use-preview-2025-03-11",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": null,
    "effective_to": null,
    "capabilities": []
  },
  {
    "api_model_id": "openai/curie",
    "provider_api_model_id": "openai:openai/curie",
    "provider_model_slug": "curie",
    "internal_model_id": "openai/curie-2020-06-11",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": "text",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2020-06-11T00:00:00",
    "effective_to": "2024-01-04T00:00:00",
    "capabilities": []
  },
  {
    "api_model_id": "openai/dall-e-2",
    "provider_api_model_id": "openai:openai/dall-e-2",
    "provider_model_slug": "dall-e-2",
    "internal_model_id": "openai/dall-e-2-2022-09-28",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": "text",
    "output_modalities": "image",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2022-09-28T00:00:00",
    "effective_to": "2026-05-12T00:00:00",
    "capabilities": []
  },
  {
    "api_model_id": "openai/dall-e-3",
    "provider_api_model_id": "openai:openai/dall-e-3",
    "provider_model_slug": "dall-e-3",
    "internal_model_id": "openai/dall-e-3-2023-10-19",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": "text",
    "output_modalities": "image",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2023-10-19T00:00:00",
    "effective_to": "2026-05-12T00:00:00",
    "capabilities": []
  },
  {
    "api_model_id": "openai/davinci",
    "provider_api_model_id": "openai:openai/davinci",
    "provider_model_slug": "davinci",
    "internal_model_id": "openai/davinci-2020-06-11",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": "text",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2020-06-11T00:00:00",
    "effective_to": "2024-01-04T00:00:00",
    "capabilities": []
  },
  {
    "api_model_id": "openai/gpt-3.5-turbo-2023-03-21",
    "provider_api_model_id": "openai:openai/gpt-3.5-turbo-2023-03-21",
    "provider_model_slug": null,
    "internal_model_id": "openai/gpt-3-5-turbo-2023-03-21",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": "text",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2023-03-21T00:00:00",
    "effective_to": null,
    "capabilities": []
  },
  {
    "api_model_id": "openai/gpt-3.5-turbo-2023-09-28",
    "provider_api_model_id": "openai:openai/gpt-3.5-turbo-2023-09-28",
    "provider_model_slug": null,
    "internal_model_id": "openai/gpt-3-5-turbo-2023-09-28",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": "text",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2023-09-28T00:00:00",
    "effective_to": "2026-09-28T00:00:00",
    "capabilities": []
  },
  {
    "api_model_id": "openai/gpt-4o-audio-2024-10-01",
    "provider_api_model_id": "openai:openai/gpt-4o-audio-2024-10-01",
    "provider_model_slug": "gpt-4o-audio-preview-2024-10-01",
    "internal_model_id": "openai/gpt-4o-audio-2024-10-01",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": "text,audio",
    "output_modalities": "text,audio",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2024-10-01T00:00:00",
    "effective_to": "2025-10-10T00:00:00",
    "capabilities": []
  },
  {
    "api_model_id": "openai/gpt-4o-audio-2024-12-17",
    "provider_api_model_id": "openai:openai/gpt-4o-audio-2024-12-17",
    "provider_model_slug": "gpt-4o-audio-preview-2024-12-17",
    "internal_model_id": "openai/gpt-4o-audio-2024-12-17",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": "text,audio",
    "output_modalities": "text,audio",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2024-12-17T00:00:00",
    "effective_to": null,
    "capabilities": []
  },
  {
    "api_model_id": "openai/gpt-4o-audio-2025-06-03",
    "provider_api_model_id": "openai:openai/gpt-4o-audio-2025-06-03",
    "provider_model_slug": "gpt-4o-audio-preview-2025-06-03",
    "internal_model_id": "openai/gpt-4o-audio-2025-06-03",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": "text,audio",
    "output_modalities": "text,audio",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2025-06-03T00:00:00",
    "effective_to": null,
    "capabilities": []
  },
  {
    "api_model_id": "openai/gpt-4o-mini-audio-preview",
    "provider_api_model_id": "openai:openai/gpt-4o-mini-audio-preview",
    "provider_model_slug": "gpt-4o-mini-audio-preview-2024-12-17",
    "internal_model_id": "openai/gpt-4o-mini-audio-preview-2024-12-17",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": "text,audio",
    "output_modalities": "text,audio",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": null,
    "effective_to": null,
    "capabilities": []
  },
  {
    "api_model_id": "openai/gpt-4o-mini-realtime-preview",
    "provider_api_model_id": "openai:openai/gpt-4o-mini-realtime-preview",
    "provider_model_slug": "gpt-4o-mini-realtime-preview-2024-12-17",
    "internal_model_id": "openai/gpt-4o-mini-realtime-preview-2024-12-17",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": "text,audio",
    "output_modalities": "text,audio",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": null,
    "effective_to": null,
    "capabilities": []
  },
  {
    "api_model_id": "openai/gpt-4o-mini-search-preview",
    "provider_api_model_id": "openai:openai/gpt-4o-mini-search-preview",
    "provider_model_slug": "gpt-4o-search-preview-2025-03-11",
    "internal_model_id": "openai/gpt-4o-mini-search-preview-2025-03-11",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": null,
    "output_modalities": null,
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": null,
    "effective_to": null,
    "capabilities": []
  },
  {
    "api_model_id": "openai/gpt-4o-mini-transcribe",
    "provider_api_model_id": "openai:openai/gpt-4o-mini-transcribe",
    "provider_model_slug": "gpt-4o-mini-transcribe",
    "internal_model_id": "openai/gpt-4o-mini-transcribe-2025-12-15",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": "text,audio",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": null,
    "effective_to": null,
    "capabilities": []
  },
  {
    "api_model_id": "openai/gpt-4o-mini-tts",
    "provider_api_model_id": "openai:openai/gpt-4o-mini-tts",
    "provider_model_slug": "gpt-4o-mini-tts",
    "internal_model_id": "openai/gpt-4o-mini-tts-2025-12-15",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": "text",
    "output_modalities": "audio",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": null,
    "effective_to": null,
    "capabilities": []
  },
  {
    "api_model_id": "openai/gpt-4o-search-preview",
    "provider_api_model_id": "openai:openai/gpt-4o-search-preview",
    "provider_model_slug": "gpt-4o-search-preview-2025-03-11",
    "internal_model_id": "openai/gpt-4o-search-preview-2025-03-11",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": "text",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": null,
    "effective_to": null,
    "capabilities": []
  },
  {
    "api_model_id": "openai/gpt-4o-transcribe",
    "provider_api_model_id": "openai:openai/gpt-4o-transcribe",
    "provider_model_slug": "gpt-4o-transcribe",
    "internal_model_id": "openai/gpt-4o-transcribe-2025-03-20",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": "text,audio",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": null,
    "effective_to": null,
    "capabilities": []
  },
  {
    "api_model_id": "openai/gpt-4-turbo-2023-03-14",
    "provider_api_model_id": "openai:openai/gpt-4-turbo-2023-03-14",
    "provider_model_slug": null,
    "internal_model_id": "openai/gpt-4-turbo-2023-03-14",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": null,
    "output_modalities": null,
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2023-03-14T00:00:00",
    "effective_to": null,
    "capabilities": []
  },
  {
    "api_model_id": "openai/gpt-4-turbo-2023-11-06",
    "provider_api_model_id": "openai:openai/gpt-4-turbo-2023-11-06",
    "provider_model_slug": null,
    "internal_model_id": "openai/gpt-4-turbo-2023-11-06",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": null,
    "output_modalities": null,
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2023-11-06T00:00:00",
    "effective_to": null,
    "capabilities": []
  },
  {
    "api_model_id": "openai/gpt-4-turbo-2024-01-25",
    "provider_api_model_id": "openai:openai/gpt-4-turbo-2024-01-25",
    "provider_model_slug": null,
    "internal_model_id": "openai/gpt-4-turbo-2024-01-25",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": null,
    "output_modalities": null,
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2024-01-25T00:00:00",
    "effective_to": null,
    "capabilities": []
  },
  {
    "api_model_id": "openai/gpt-audio",
    "provider_api_model_id": "openai:openai/gpt-audio",
    "provider_model_slug": "gpt-audio-2025-08-28",
    "internal_model_id": "openai/gpt-audio-2025-08-28",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": "text,audio",
    "output_modalities": "text,audio",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": null,
    "effective_to": null,
    "capabilities": []
  },
  {
    "api_model_id": "openai/gpt-audio-mini-2025-10-06",
    "provider_api_model_id": "openai:openai/gpt-audio-mini-2025-10-06",
    "provider_model_slug": "gpt-audio-mini-2025-10-06",
    "internal_model_id": "openai/gpt-audio-mini-2025-10-06",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": "text,audio",
    "output_modalities": "text,audio",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2025-10-06T00:00:00",
    "effective_to": null,
    "capabilities": []
  },
  {
    "api_model_id": "openai/gpt-image-1",
    "provider_api_model_id": "openai:openai/gpt-image-1",
    "provider_model_slug": "gpt-image-1",
    "internal_model_id": "openai/gpt-image-1-2025-04-23",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "image",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": null,
    "effective_to": null,
    "capabilities": []
  },
  {
    "api_model_id": "openai/gpt-image-1.5",
    "provider_api_model_id": "openai:openai/gpt-image-1.5",
    "provider_model_slug": "gpt-image-1.5-2025-12-16",
    "internal_model_id": "openai/gpt-image-1-5-2025-12-16",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text,image",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2025-12-16T00:00:00",
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "image.generate",
        "status": "active",
        "params": []
      },
      {
        "capability_id": "image.edit",
        "status": "active",
        "params": []
      }
    ]
  },
  {
    "api_model_id": "openai/gpt-image-1-mini-2025-10-06",
    "provider_api_model_id": "openai:openai/gpt-image-1-mini-2025-10-06",
    "provider_model_slug": "gpt-image-1-mini",
    "internal_model_id": "openai/gpt-image-1-mini-2025-10-06",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "image",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2025-10-06T00:00:00",
    "effective_to": null,
    "capabilities": []
  },
  {
    "api_model_id": "openai/gpt-realtime",
    "provider_api_model_id": "openai:openai/gpt-realtime",
    "provider_model_slug": "gpt-realtime-2025-08-28",
    "internal_model_id": "openai/gpt-realtime-2025-08-28",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": "text,image,audio",
    "output_modalities": "text,audio",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": null,
    "effective_to": null,
    "capabilities": []
  },
  {
    "api_model_id": "openai/gpt-realtime-mini-2025-10-06",
    "provider_api_model_id": "openai:openai/gpt-realtime-mini-2025-10-06",
    "provider_model_slug": "gpt-realtime-mini-2025-10-06",
    "internal_model_id": "openai/gpt-realtime-mini-2025-10-06",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": "text,image,audio",
    "output_modalities": "text,audio",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2025-10-06T00:00:00",
    "effective_to": null,
    "capabilities": []
  },
  {
    "api_model_id": "openai/sora-2-2025-09-30",
    "provider_api_model_id": "openai:openai/sora-2-2025-09-30",
    "provider_model_slug": "sora-2",
    "internal_model_id": "openai/sora-2-2025-09-30",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": null,
    "output_modalities": null,
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2025-09-30T00:00:00",
    "effective_to": null,
    "capabilities": []
  },
  {
    "api_model_id": "openai/sora-2-pro-2025-10-03",
    "provider_api_model_id": "openai:openai/sora-2-pro-2025-10-03",
    "provider_model_slug": "sora-2-pro",
    "internal_model_id": "openai/sora-2-pro-2025-10-03",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": null,
    "output_modalities": null,
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": "2025-10-03T00:00:00",
    "effective_to": null,
    "capabilities": []
  },
  {
    "api_model_id": "openai/tts-1",
    "provider_api_model_id": "openai:openai/tts-1",
    "provider_model_slug": "tts-1",
    "internal_model_id": "openai/tts-1-2023-11-06",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": null,
    "output_modalities": null,
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": null,
    "effective_to": null,
    "capabilities": []
  },
  {
    "api_model_id": "openai/tts-1-hd",
    "provider_api_model_id": "openai:openai/tts-1-hd",
    "provider_model_slug": "tts-1-hd",
    "internal_model_id": "openai/tts-1-hd-2023-11-06",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": null,
    "output_modalities": null,
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": null,
    "effective_to": null,
    "capabilities": []
  },
  {
    "api_model_id": "openai/whisper-1",
    "provider_api_model_id": "openai:openai/whisper-1",
    "provider_model_slug": "whisper-1",
    "internal_model_id": "openai/whisper-1-2023-03-01",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": null,
    "output_modalities": null,
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": null,
    "effective_to": null,
    "capabilities": []
  },
  {
    "api_model_id": "openai/o1-mini",
    "provider_api_model_id": "openai:openai/o1-mini",
    "provider_model_slug": null,
    "internal_model_id": "openai/o1-mini-2024-09-12",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": null,
    "output_modalities": null,
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": null,
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": [
          {
            "param_id": "max_tokens",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "response_format",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "seed",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          },
          {
            "param_id": "structured_outputs",
            "provider_min": null,
            "provider_max": null,
            "provider_default": null,
            "notes": null
          }
        ]
      }
    ]
  },
  {
    "api_model_id": "openai/gpt-5.3-codex",
    "provider_api_model_id": "openai:openai/gpt-5.3-codex",
    "provider_model_slug": "gpt-5.3-codex",
    "internal_model_id": "openai/gpt-5-3-codex-2026-02-05",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": null,
    "effective_to": null,
    "capabilities": [
      {
        "capability_id": "text.generate",
        "status": "active",
        "params": []
      }
    ]
  },
  {
    "api_model_id": "openai/gpt-5.3",
    "provider_api_model_id": "openai:openai/gpt-5.3",
    "provider_model_slug": null,
    "internal_model_id": "openai/gpt-5-3",
    "is_active_gateway": false,
    "quantization_scheme": null,
    "input_modalities": "text,image",
    "output_modalities": "text",
    "context_length": null,
    "max_output_tokens": null,
    "effective_from": null,
    "effective_to": null,
    "capabilities": []
  }
]