{
  "model_id": "mistral/mistral-small-3-2-2025-06-20",
  "organisation_id": "mistral",
  "name": "Mistral Small 3.2",
  "status": "Available",
  "previous_model_id": null,
  "announced_date": "2025-06-20T00:00:00",
  "release_date": "2025-06-20T00:00:00",
  "deprecation_date": null,
  "retirement_date": null,
  "license": "Apache 2.0",
  "input_types": "text,image",
  "output_types": "text",
  "links": [
    {
      "platform": "weights",
      "url": "https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506"
    }
  ],
  "details": [
    {
      "name": "input_context_length",
      "value": 128000
    },
    {
      "name": "output_context_length",
      "value": 128000
    },
    {
      "name": "parameter_count",
      "value": 24000000000
    }
  ],
  "benchmarks": [
    {
      "benchmark_id": "ai2d",
      "score": 0.9291,
      "is_self_reported": true,
      "other_info": null,
      "source_link": "https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506",
      "rank": 1
    },
    {
      "benchmark_id": "chartqa",
      "score": 0.874,
      "is_self_reported": true,
      "other_info": null,
      "source_link": "https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506",
      "rank": 1
    },
    {
      "benchmark_id": "docvqa",
      "score": 0.9486,
      "is_self_reported": true,
      "other_info": null,
      "source_link": "https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506",
      "rank": 1
    },
    {
      "benchmark_id": "eqbench",
      "score": 1126.5,
      "is_self_reported": false,
      "other_info": null,
      "source_link": "https://eqbench.com",
      "rank": 14
    },
    {
      "benchmark_id": "gpqa",
      "score": 0.4422,
      "is_self_reported": true,
      "other_info": "5 Shot CoT",
      "source_link": "https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506",
      "rank": 1
    },
    {
      "benchmark_id": "gpqa-diamond",
      "score": 0.4613,
      "is_self_reported": true,
      "other_info": null,
      "source_link": "https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506",
      "rank": 54
    },
    {
      "benchmark_id": "humaneval",
      "score": 0.929,
      "is_self_reported": true,
      "other_info": "Pass@5",
      "source_link": "https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506",
      "rank": 1
    },
    {
      "benchmark_id": "math",
      "score": 0.6942,
      "is_self_reported": true,
      "other_info": "5 Shot CoT",
      "source_link": "https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506",
      "rank": 1
    },
    {
      "benchmark_id": "mathvista",
      "score": 0.6709,
      "is_self_reported": true,
      "other_info": null,
      "source_link": "https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506",
      "rank": 1
    },
    {
      "benchmark_id": "mmlu",
      "score": 0.805,
      "is_self_reported": true,
      "other_info": null,
      "source_link": "https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506",
      "rank": 7
    },
    {
      "benchmark_id": "mmlu-pro",
      "score": 0.6906,
      "is_self_reported": true,
      "other_info": "5 Shot CoT",
      "source_link": "https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506",
      "rank": 8
    },
    {
      "benchmark_id": "mmmu",
      "score": 0.625,
      "is_self_reported": true,
      "other_info": null,
      "source_link": "https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506",
      "rank": 13
    },
    {
      "benchmark_id": "simpleqa",
      "score": 0.121,
      "is_self_reported": true,
      "other_info": "TotalAcc",
      "source_link": "https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506",
      "rank": 9
    }
  ]
}